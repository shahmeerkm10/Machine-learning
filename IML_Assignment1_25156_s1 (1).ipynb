{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IML Kaggle Challenge 1**\n",
        "Instructor : Miss Solat Jabeen Sheikh\n"
      ],
      "metadata": {
        "id": "7OnJaJx0H8d_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERP: 25156\n"
      ],
      "metadata": {
        "id": "trHN-ZJzIVmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Shahmeer Khan"
      ],
      "metadata": {
        "id": "SusB5rZLIZeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle username: ShahmeerKhan10"
      ],
      "metadata": {
        "id": "iHZPkcKP3rgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Base description**\n",
        "This notebook works to test the several different models given to us to achieve the best possible score on the provided dataset, the attempted models and their relevant code is present in the notebook but commented to clear confusion, the best performing model along with its relevant hyperparameters is left uncommented. Due to the work being done via google colab , the csv files were uploaded to drive and then accessed through drive.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pIKUimteIboY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHfLCRB6daUs",
        "outputId": "8d12068d-198e-436d-adf4-1d723e77b61b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive mounted to access the relevant csv files for the models"
      ],
      "metadata": {
        "id": "8P_rk70tJZvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm          # For LightGB\n",
        "!pip install imbalanced-learn  # For SMOTE\n",
        "!pip install scikit-learn      # For metrics and model selection (f1_score, cross_val_score, StratifiedKFold, ExtraTreesClassifier)\n",
        "!pip install xgboost           # For XGBClassifier\n",
        "!pip install catboost          # For CatBoostClassifier\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvdHXdP9wiQw",
        "outputId": "b7bb3212-6702-46c3-9af5-dce27a832043"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing all other relevant packages for model training/testing, some of these were needed for GPU usage.\n"
      ],
      "metadata": {
        "id": "pvskGfNhJf4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dask[dataframe]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB8mzmDn4Yvg",
        "outputId": "9436d35e-4511-47a0-d157-06e3a6d07937"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.1.16)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dask dataframe installed for parallel computing, attempted the use of GPU instead of this but time limits restricted much use."
      ],
      "metadata": {
        "id": "H1J2W4pfJwLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n"
      ],
      "metadata": {
        "id": "A12yXb4sajlb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the train and test files\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/train_set.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/test_set.csv\")\n",
        "\n",
        "# Splitting data into features (F) and target variable (T)\n",
        "F = df1.drop(columns=['Y'])\n",
        "T = df1['Y']"
      ],
      "metadata": {
        "id": "pY63e5xhbMsB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the above stated csv files, due to the usage of colab, they had to be read through drive"
      ],
      "metadata": {
        "id": "0C_WIzxGbUYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models and parameters used for training and testing**\n",
        "This section includes all the models, scaling, imputation techniques, feature reduction etc that didn't give contribute to the final best score"
      ],
      "metadata": {
        "id": "QaVgLhsEbty2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation techniques\n",
        "\n",
        "#Option 1: Mean imputation\n",
        "#imputer = SimpleImputer(strategy='mean')\n",
        "#F = imputer.fit_transform(F)\n",
        "#df2 = imputer.fit_transform(df2)\n",
        "\n",
        "#Option 2: Median imputation\n",
        "#imputer = SimpleImputer(strategy='median')\n",
        "#F = imputer.fit_transform(F)\n",
        "#df2 = imputer.fit_transform(df2)\n"
      ],
      "metadata": {
        "id": "Thmvi4iWcEYS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While both of these imputation techniques did improve the final results, they were far too generalized as opposed to KNN which gave way better results, though significantly time efficient, the output scores weren't better than KNN"
      ],
      "metadata": {
        "id": "5Ujs0ukcb1QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling techniques\n",
        "\n",
        "# MinMax Scaler\n",
        "#scaler = MinMaxScaler()\n",
        "#F = scaler.fit_transform(F)\n",
        "#df2 = scaler.fit_transform(df2)\n",
        "\n",
        "#Option 2 : Standard Scaler\n",
        "#scaler = StandardScaler()\n",
        "#F = scaler.fit_transform(F)\n",
        "#df2 = scaler.fit_transform(df2)\n",
        "\n",
        "#Option 3: Robust Scaler\n",
        "#scaler = RobustScaler()\n",
        "#F = scaler.fit_transform(F)\n",
        "#df2 = scaler.fit_transform(df2)"
      ],
      "metadata": {
        "id": "zpTRL8wucefE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case for some reason scaling the data had a negative effect, it could be due to my preference for tree based models like LightGB and XGboost etc which dont focus on the absolute values, in turn scaling could change the relative differences in feature values that trees naturally capture therefore lowering the score, therefore no scaling was used for the final best result."
      ],
      "metadata": {
        "id": "Ipn2x8lsclOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA for feature reduction\n",
        "\n",
        "# Applying PCA to reduce dimensionality\n",
        "#n_components = 55\n",
        "#pca = PCA(n_components=n_components)\n",
        "#F = pca.fit_transform(F)\n",
        "#df2 = pca.transform(df2)"
      ],
      "metadata": {
        "id": "gykVPdYGdHUa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While PCA was very efficient time-wise, it faced a similar issue where the reduced features were too diluted thus losing important relationships between features that tree based models usually rely on. It performed way faster but that loss of relationships ended up affecting the score for my final selected model."
      ],
      "metadata": {
        "id": "I5Q3p3PPdXJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Algorithm based feature reduction\n",
        "\n",
        "# Random Forest feature reduction\n",
        "#rf = RandomForestClassifier(n_estimators=200, random_state=2)\n",
        "#rf.fit(F, T)  # F is your feature matrix, T is the target variable\n",
        "\n",
        "# Gradient Boosting feature reduction\n",
        "#gb= GradientBoostingClassifier(n_estimators=200, random_state=2)\n",
        "#gb.fit(F, T)\n",
        "\n",
        "# LightGB reduction\n",
        "#lgb = LGBMClassifier(num_leaves=60,learning_rate=0.1,n_estimators=1000,max_depth=12,subsample=0.9,colsample_bytree=1.0,random_state=2,reg_alpha=0.1,reg_lambda=0.1)\n",
        "#lgb.fit(F, T)\n",
        "\n",
        "# Feature Selection using CatBoost\n",
        "#cb= CatBoostClassifier(max_depth=4,learning_rate=0.05,n_estimators=700,subsample=0.9,colsample_bylevel=1.0,random_seed=2,reg_lambda=0.5)\n",
        "#cb.fit(F, T)\n",
        "\n",
        "# Extra Trees feature reduction\n",
        "#et = ExtraTreesClassifier(n_estimators=700,max_depth=4 ,max_features=0.8,min_samples_split=2,random_state=2, n_jobs=-1)\n",
        "#et.fit(F, T)\n",
        "\n",
        "# Decision Tree feature reduction\n",
        "#dt_initial = DecisionTreeClassifier(criterion='gini', max_depth=100, min_samples_split=10, min_samples_leaf=5)\n",
        "#dt_initial.fit(F, T_)\n"
      ],
      "metadata": {
        "id": "NOm2IYted8E0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALgorithm based feature reduction ended up proving way more fruitful as it captured the importance of features relative to the model they were to be trained on, with every new model i tried, i used it for feature selection aswell. While all of these performed well, they didnt make the final cut for the best performing model."
      ],
      "metadata": {
        "id": "p85Cq3P2eluD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and test sets (70/30 split)\n",
        "#trainF, testF, trainT, testT = train_test_split(F, T, test_size=0.3, random_state=2, stratify=T)"
      ],
      "metadata": {
        "id": "XS3PdzMXe_mz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found out there was no need for splitting as we were already provided with the relevant train and test set, further splitting made it lose more training data which affected my score negatively"
      ],
      "metadata": {
        "id": "nM-HC4QPfYej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for class imbalance in the target variable\n",
        "class_counts = T.value_counts()\n",
        "print(\"Class distribution in target variable:\")\n",
        "print(class_counts)\n",
        "\n",
        "# Displaying percentage distribution\n",
        "class_percentages = T.value_counts(normalize=True) * 100\n",
        "print(\"\\nClass distribution percentages:\")\n",
        "print(class_percentages)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgAX-01gZ49",
        "outputId": "76894526-d4bb-4613-8863-8d3ea32b1a10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in target variable:\n",
            "Y\n",
            "0    245473\n",
            "1       649\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution percentages:\n",
            "Y\n",
            "0    99.73631\n",
            "1     0.26369\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classes were heavily imbalanced in this dataset as we can see here with the ratio of 245,473 to 649, this made me believe they needed to be balanced.\n"
      ],
      "metadata": {
        "id": "bGWnlqF8gbZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Class imbalance\n",
        "\n",
        "#class_weight='balanced'\n",
        "\n",
        "# Applying SMOTE to the training data to handle class imbalance\n",
        "#smote = SMOTE(random_state=2)\n",
        "#F_r, T_r = smote.fit_resample(F_reduced, T)\n"
      ],
      "metadata": {
        "id": "Wu9qGLpzfy4j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first cloice was to use the class_weight hyperparameter however it wasnt the best choice as this is used for slightly imbalanced classes, the second choice SMOTE is the go to standard for handling such a large class imbalance, however it ended up reducing the score, this could be due to it overfitting the minority class instead but i'm not too sure, either way my final result woked out better without balancing.\n"
      ],
      "metadata": {
        "id": "j6T_9OmZf-T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Models with respective hyperparameters\n",
        "\n",
        "# Decision tree\n",
        "#dt_final = DecisionTreeClassifier(criterion='gini', max_depth=100, min_samples_split=10, min_samples_leaf=5)\n",
        "\n",
        "#NAIVE BAYES\n",
        "#nb_final = GaussianNB()\n",
        "\n",
        "# RANDOM FOREST\n",
        "#rf_final = RandomForestClassifier(n_estimators=700, criterion='gini', max_depth=25, min_samples_split=5, min_samples_leaf=2,max_features='sqrt', random_state=2,class_weight='balanced')\n",
        "\n",
        "# Gradient Boosting\n",
        "#gb_final = GradientBoostingClassifier(n_estimators=500, learning_rate=0.05, max_depth=8, random_state=2)\n",
        "\n",
        "# KNN classifier\n",
        "#knn_final = KNeighborsClassifier(n_neighbors=15, weights='distance', algorithm='auto',metric='manhattan')\n",
        "\n",
        "# AdaBoost classifier with a Decision Tree as the base estimator\n",
        "#base_estimator = DecisionTreeClassifier(max_depth=2)  # Shallow tree as base estimator\n",
        "#ada_final = AdaBoostClassifier(estimator=base_estimator, n_estimators=200, learning_rate=0.05, random_state=2, algorithm=\"SAMME\")\n",
        "\n",
        "# Catboost classifier\n",
        "#cb_final = CatBoostClassifier(max_depth=8,learning_rate=0.01,n_estimators=1500,subsample=0.8,colsample_bylevel=0.8,random_seed=2,reg_lambda=2.0)\n",
        "\n",
        "# BaggingClassifier with XGBoost as the base estimator\n",
        "#bag_final = BaggingClassifier(estimator=estimator,n_estimators=15,max_samples=0.8,max_features=0.8,random_state=2,n_jobs=-1)\n",
        "\n",
        "# Extra Trees Classifier\n",
        "#et_final = ExtraTreesClassifier(n_estimators=1500,max_depth=15,max_features=0.7,min_samples_split=5,min_samples_leaf=3,random_state=2,n_jobs=-1)\n",
        "\n",
        "# Stacking classifier with the base models and meta-model\n",
        "#stacked_final = StackingClassifier(estimators=[('xgboost', xgb_final),('lightgbm', lgb_final),('catboost',cb_final)],final_estimator=LogisticRegression(max_iter=100),cv=5,n_jobs=-1)"
      ],
      "metadata": {
        "id": "VQz0uU8OhZG1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore the hyperparameters as they dont represent the respective best attempt for each algorithm, they act as placeholders. Algorithm analysis:\n",
        "\n",
        "\n",
        "*   Decision tree, worked well and relatively fast, efficiency depended on the depth of the tree, however was't the highest scoring algorithm due to not capturing the relationships between features too well\n",
        "\n",
        "*   Naive Bayes, again worked really efficiently, not many hyperparameters to tune , so couldn't play around with many possibilities and testing, used with PCA for feature reduction, less extensive code decent results\n",
        "\n",
        "*   Random forest, not that fast of an algorithm, had really high hopes for it but was let down, attempted several hyperparameters got high ROC but really low scores, attempted PCA based feature reduction, didnt help much, this was before i tried algo based feature reduction so maybe could have gotten good results with that.\n",
        "\n",
        "*   Gradient boosting, faster than random forest and performed significantly better too, at this point i was still referring to PCA for feature selection which i learned to improve later on.\n",
        "\n",
        "*   KNN classifier, one of the worst performing models, took a lot of time and varying amounts of neighbors did barely anything to change the low scores, used with and without PCA, both leaving much to be desired.\n",
        "\n",
        "*   Adaboost classifier, one of my first good results with a model buts till had alot to improve on, fast execution but not amazing results, reason explained later on.\n",
        "\n",
        "*   Bagging classifier, expected higher performance as it took way longer than the base estimator used i.e. XGboost but not much improvement was seen\n",
        "\n",
        "*   Extra trees classifier, expected alot more like random forest but again not great results\n",
        "\n",
        "*   Stacking, had the highest hopes for this as it works on an ensemble of models but was let down as the excessive training time to process multiple models didnt give the strongest score at the end, performed well but not the best\n",
        "\n",
        "*   Decent results but expected more like adaboost, took some time to process based on higher hyperparameters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DiwVCEIbi_sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Best performance code**\n",
        "Includes best hyperparameters, model(s), imputation scaling etc for the best produced resulting code\n"
      ],
      "metadata": {
        "id": "rqhJblIIrYlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 3: KNN imputation (best submission)\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "F = imputer.fit_transform(F)\n",
        "df2 = imputer.fit_transform(df2)"
      ],
      "metadata": {
        "id": "pp6d7Wfrr3p8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best imputation technique out of the three used, 5 was the perfect amount of neighbors, any higher or lower messed up the score, although it took longer to process, was worth it for the perforamnce gain in the end."
      ],
      "metadata": {
        "id": "INNZBpCMr-YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost for feature selection (best submission)\n",
        "xgb = XGBClassifier(max_depth=4,learning_rate=0.05,n_estimators=700,subsample=0.9,colsample_bytree=1.0,random_state=2,reg_alpha=0.5,reg_lambda=0.5,n_jobs=-1)\n",
        "xgb.fit(F, T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "6H6izdh9sRsA",
        "outputId": "04c7b449-2ca1-4b78-b19b-e77fbfa30942"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=700, n_jobs=-1,\n",
              "              num_parallel_tree=None, random_state=2, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=700, n_jobs=-1,\n",
              "              num_parallel_tree=None, random_state=2, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=700, n_jobs=-1,\n",
              "              num_parallel_tree=None, random_state=2, ...)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best algo based feature selection, as i used this for XGboost on its own and in voting too."
      ],
      "metadata": {
        "id": "NSY1VoiUsVmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances and select the top k most apply to reduced dataset\n",
        "\n",
        "#F = F.values (needed for catboost feature reduction)\n",
        "#df2 = df2.values (needed for catboost feature reduction)\n",
        "\n",
        "importances = xgb.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]  # Sort in descending order of importance\n",
        "k = 46 #(best submission)\n",
        "top_k_indices = indices[:k]\n",
        "F_reduced = F[:, top_k_indices]  # For training data\n",
        "df2_reduced = df2[:, top_k_indices]  # For test data"
      ],
      "metadata": {
        "id": "xp--PR1DsgTD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "46 was the perfect amount of features needed to get the optimal result, some models needed all the features to perform well but XGboost preferred 46. F and df2 dataframes had to be converted to arrays for catboost feature reduction."
      ],
      "metadata": {
        "id": "MEq9RUa_sv8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Key LightGBM parameters\n",
        "#(best submission)\n",
        "lgb_final = LGBMClassifier(num_leaves=50,learning_rate=0.01,n_estimators=1400,max_depth=12,subsample=0.5,colsample_bytree=0.7,random_state=2,reg_alpha=1.0,reg_lambda=1.5)\n",
        "\n",
        "#(Best submission)\n",
        "#XGboost main classifier\n",
        "xgb_final = XGBClassifier(max_depth=8,learning_rate=0.006,n_estimators=2600,subsample=0.7,colsample_bytree=0.5,random_state=2,reg_alpha=2,reg_lambda=2,n_jobs=-1)"
      ],
      "metadata": {
        "id": "4-H56Z3vtBNG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The base classifiers for the voting classifier, these hyperparameters individually gave the best performances across models, a combination of the two via voting further improved on that."
      ],
      "metadata": {
        "id": "SEckUMnztYGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a VotingClassifier using soft voting (averages predicted probabilities)\n",
        "ensemble_final = VotingClassifier(estimators=[('lightgbm', lgb_final), ('xgboost', xgb_final)],voting='soft',weights=[1.3,1],n_jobs=-1) #(best submission)"
      ],
      "metadata": {
        "id": "bjod00lYtiEy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LightGB and XGboost with soft voting and adjusted weights we got the best model"
      ],
      "metadata": {
        "id": "7EU44JHUtrtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation setup (Stratified KFold to ensure balanced classes in each fold)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "\n",
        "# Perform cross-validation (ROC AUC scoring)\n",
        "cv_scores = cross_val_score(ensemble_final, F_reduced, T, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "# Output cross-validation scores\n",
        "print(f\"Cross-validation ROC AUC scores: {cv_scores}\")\n",
        "print(f\"Mean ROC AUC score from cross-validation: {cv_scores.mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPw1tHWPtxAD",
        "outputId": "9606ca8f-961b-41b9-cfa2-1f470d1421f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation ROC AUC scores: [0.96888764 0.9665255  0.95386622 0.97368032 0.96171097]\n",
            "Mean ROC AUC score from cross-validation: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially focused on the best ROC score to get an idea of how to finetune the hyperparameters, eventually resorted to Cross Validation to get a better generalized understanding, way more time consuming but also significantly better for understanding the ROC scores."
      ],
      "metadata": {
        "id": "sinfNhlQt5VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the chosen model on the dataset\n",
        "ensemble_final.fit(F_reduced, T)\n",
        "\n",
        "# Predict probabilities for the test dataset (df2)\n",
        "test_probs = ensemble_final.predict_proba(df2_reduced)[:, 1]  # Get probabilities for class 1\n"
      ],
      "metadata": {
        "id": "FT10RO1duMfC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we fit our chosen model on the data and get the probabilities for the target class, the variable ensemble_final was edited to match the model being used at time of testing."
      ],
      "metadata": {
        "id": "5xKXOqpBufmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the submission file with predicted probabilities\n",
        "df_sample = pd.read_csv(\"/content/drive/MyDrive/sample_submission.csv\")\n",
        "df_sample['Y'] = test_probs  # Use predicted probabilities\n",
        "\n",
        "# Save to CSV for submission\n",
        "df_sample.to_csv(\"/content/drive/MyDrive/submission_ensemble.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "RFmtyJddupG4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the sample submission file to enter the calculated probabilities to get the final submission file"
      ],
      "metadata": {
        "id": "aDGxwTWsut2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final thoughts and major issues faced**\n",
        "\n",
        "*   My scores were initially struggling due to the fact that i misunderstood the submission part, instead of directly inputing the probabilities, i was using an ROC based threshold to assign every element a value of 1 and 0 as i thought the final submission's Y column had to have values 0 or 1 submitted, checking the test_set.csv file in more detail gave me a better understanding of what was needed.\n",
        "\n",
        "*   Initially attempted a grid search but it took forever no matter how few hyperparameters i chose so referred to individually altering parameters as needed. Voting and stacking were still taking too long so looked for GPU options i.e. Colab in this case, which did help a bit but i reached my offered resource limit really soon, used the GPU offered by Kaggle itself but that also reached its limit really soon so had to utilize CPU resources efficiently.\n",
        "\n",
        "*   To utilize CPU well i used the dask dataframe package and also the n_jobs=-1 hyperparameter for the models which utilizes all CPU cores for execution hence aiding in reducing processing time.\n",
        "\n",
        "*   Overall score could probably be improved by testing out other models more often but i was confident in XGboost and LightGB's results and so had my main focus on them."
      ],
      "metadata": {
        "id": "RvwoHYOUu2eG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNWZubWLvrHQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}