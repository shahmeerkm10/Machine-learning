{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IML Kaggle Challenge 2**\n",
        "Instructor : Miss Solat Jabeen Sheikh"
      ],
      "metadata": {
        "id": "mMn3wxBZcZYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERP: 25156"
      ],
      "metadata": {
        "id": "e5xKFjQSccoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Shahmeer Khan"
      ],
      "metadata": {
        "id": "9ju_9YzlchcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle username: ShahmeerKhan10"
      ],
      "metadata": {
        "id": "eAfwfvGtckJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Base description**\n",
        "This notebook works to test the several different models given to us to achieve the best possible score on the provided dataset, the attempted models and their relevant code is present in the notebook but commented to clear confusion, the best performing model along with its relevant hyperparameters is left uncommented. Due to the work being done via google colab , the csv files were uploaded to drive and then accessed through drive."
      ],
      "metadata": {
        "id": "b5oOTOZlcn-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "zUWSdRBicum1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drive mounted to access the relevant csv files for the models"
      ],
      "metadata": {
        "id": "1QPDNmBqc4eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]\n",
        "!pip install lightgbm\n",
        "!pip install imbalanced-learn\n",
        "!pip install scikit-learn\n",
        "!pip install xgboost\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "9wtakZqoc4qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing all other relevant packages for model training/testing, some of these were needed for GPU usage. Dask dataframe installed for parallel computing, attempted the use of GPU instead of this but time limits restricted much use."
      ],
      "metadata": {
        "id": "gH2mg_a-dOQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "ogDfLrEFdQAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the train and test files\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/sample_submission.csv\")\n",
        "\n",
        "# Splitting data into features (F) and target variable (T)\n",
        "F = df1.drop(columns=['price_doc'])  # Features (all columns except 'price_doc')\n",
        "T = df1['price_doc']                # Target column"
      ],
      "metadata": {
        "id": "dP-r7-TmdbeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the above stated csv files, due to the usage of colab, they had to be read through drive"
      ],
      "metadata": {
        "id": "t7McanPsdvqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical columns\n",
        "categorical_columns = F.select_dtypes(include=['object', 'category', 'bool']).columns\n",
        "\n",
        "# Apply one-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "F_encoded = encoder.fit_transform(F[categorical_columns])\n",
        "df2_encoded = encoder.transform(df2[categorical_columns])\n",
        "\n",
        "# Convert encoded data into DataFrames and assign appropriate column names\n",
        "F_encoded = pd.DataFrame(F_encoded, columns=encoder.get_feature_names_out(categorical_columns), index=F.index)\n",
        "df2_encoded = pd.DataFrame(df2_encoded, columns=encoder.get_feature_names_out(categorical_columns), index=df2.index)\n",
        "\n",
        "# Concatenate the one-hot encoded columns back with the non-categorical columns\n",
        "F = pd.concat([F.drop(columns=categorical_columns), F_encoded], axis=1)\n",
        "df2 = pd.concat([df2.drop(columns=categorical_columns), df2_encoded], axis=1)\n",
        "\n",
        "# Separate the 'ID' column from the test set (df2), to be included in the submission file later\n",
        "test_ids = df2['row ID']  # Save 'ID' column for later use in submission\n",
        "\n",
        "# Align the test set columns with the training set columns\n",
        "missing_columns = set(F.columns) - set(df2.columns)\n",
        "for col in missing_columns:\n",
        "    df2[col] = 0  # Add missing columns to the test set with 0 values\n",
        "\n",
        "# Reorder columns in df2 to match the order of the training set\n",
        "df2 = df2[F.columns]"
      ],
      "metadata": {
        "id": "m_v_GMf-dh3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This entire process was part of the best submission which used all feature columns and via one hot encoding converted the categorical ones too."
      ],
      "metadata": {
        "id": "0cQBn56Pd0GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop categorical columns from both train and test sets\n",
        "#F = F.drop(columns=categorical_columns)\n",
        "#df2 = df2.drop(columns=categorical_columns)"
      ],
      "metadata": {
        "id": "pgIf-fVEd9Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried some runs with simply dropping the categorical columns aswell"
      ],
      "metadata": {
        "id": "VK0pNhyveFm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models and parameters used for training and testing**\n",
        "This section includes all the models, scaling, imputation techniques, feature reduction etc that didn't give contribute to the final best score"
      ],
      "metadata": {
        "id": "jpgEF7bTeVkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation techniques\n",
        "\n",
        "#Option 1: Mean imputation\n",
        "#imputer = SimpleImputer(strategy='mean')\n",
        "#F = imputer.fit_transform(F)\n",
        "#df2 = imputer.fit_transform(df2)\n",
        "\n",
        "#Option 2: Median imputation\n",
        "#imputer = SimpleImputer(strategy='median')\n",
        "#F = imputer.fit_transform(F)\n",
        "#df2 = imputer.fit_transform(df2)"
      ],
      "metadata": {
        "id": "vn3M1RdIeX9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While both of these imputation techniques did improve the final results, they were far too generalized as opposed to KNN which gave way better results, though significantly time efficient, the output scores weren't better than KNN"
      ],
      "metadata": {
        "id": "YXdOsZEUefhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling techniques\n",
        "\n",
        "#Option 2 : Standard Scaler\n",
        "#scaler = StandardScaler()\n",
        "#F = scaler.fit_transform(F)\n",
        "#df2 = scaler.fit_transform(df2)\n",
        "\n",
        "#Option 3: Robust Scaler\n",
        "#scaler = RobustScaler()\n",
        "#F = scaler.fit_transform(F)\n",
        "#df2 = scaler.fit_transform(df2)"
      ],
      "metadata": {
        "id": "BN_Su6xhegRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the data had a net positive effect, different scalers yielded different results but the best performing one ( minmax scaler ) is mentioned later on"
      ],
      "metadata": {
        "id": "K98vj4NHeoXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA for feature reduction\n",
        "\n",
        "# Applying PCA to reduce dimensionality\n",
        "#n_components = 150\n",
        "#pca = PCA(n_components=n_components)\n",
        "#F = pca.fit_transform(F)\n",
        "#df2 = pca.transform(df2)"
      ],
      "metadata": {
        "id": "8O9bIs-Te4hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While feature selection using PCA did help with other models, it had no benefit to my final submission of random forest, this variant of PCA mentiones the components directly."
      ],
      "metadata": {
        "id": "NU9LtKCgfhuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA for feature reduction (variance)\n",
        "\n",
        "# Applying PCA to reduce dimensionality\n",
        "#pca = PCA(n_components=0.95)\n",
        "#F = pca.fit_transform(F)\n",
        "#df2 = pca.transform(df2)"
      ],
      "metadata": {
        "id": "7ioE5wp0frpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This version of PCA uses variance as an input, again not too useful"
      ],
      "metadata": {
        "id": "2F6yHfPgfwbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Algorithm based feature reduction\n",
        "\n",
        "# GB boost for feature selection\n",
        "#gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, min_samples_split=5, min_samples_leaf=3, subsample=0.8, random_state=42);\n",
        "#gb.fit(F, T);\n",
        "\n",
        "# XG boost features\n",
        "#xgb = XGBRegressor(n_estimators=80, learning_rate=0.05, max_depth=8, subsample=0.8, colsample_bytree=0.8, random_state=42, objective=\"reg:squarederror\");\n",
        "#xgb.fit(F, T);\n",
        "\n",
        "# random forest feature selection\n",
        "#rf = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_split=10, min_samples_leaf=3, max_features=0.5, random_state=42, n_jobs=-1 )\n",
        "#rf.fit(F, T)\n"
      ],
      "metadata": {
        "id": "TFRnkSZlf1n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances and select the top k most apply to reduced dataset\n",
        "#importances = xgb.feature_importances_\n",
        "#indices = np.argsort(importances)[::-1]  # Sort in descending order of importance\n",
        "#k = 200 #(best submission)\n",
        "#top_k_indices = indices[:k]\n",
        "#F = F[:, top_k_indices]  # For training data\n",
        "#df2 = df2[:, top_k_indices]  # For test data"
      ],
      "metadata": {
        "id": "JiPcVYwVgOMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using these algo specific feature reduction methods, i attempted feature selection by picking k top indices however as my best submission used all features, this wasnt too beneficial"
      ],
      "metadata": {
        "id": "C1y2i_5sgQ_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For polynomial regression\n",
        "\n",
        "# Generate Polynomial Features\n",
        "#poly = PolynomialFeatures(degree=3)  # Change degree as needed\n",
        "#F_poly = poly.fit_transform(F)  # Apply polynomial transformation\n",
        "\n",
        "# Generate Polynomial Features for the test set (after PCA transformation)\n",
        "#df2_poly = poly.transform(df2)\n",
        "\n",
        "# Train the model on the reduced feature set\n",
        "#poly_final = LinearRegression()\n",
        "\n",
        "# Cross-validation to evaluate RMSE\n",
        "#cv_scores = cross_val_score(poly_final, F_poly, T, cv=5, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "# Convert negative RMSE to positive and compute the mean RMSE\n",
        "#rmse_cv = -cv_scores.mean()\n",
        "\n",
        "#print(f\"Cross-validated RMSE for Polynomial Regression (Degree={2}): {rmse_cv}\")\n",
        "\n",
        "#poly_final.fit(F_poly, T)\n",
        "\n",
        "#predicition for polynomial regression\n",
        "#predictions = poly_final.predict(df2_poly)"
      ],
      "metadata": {
        "id": "Mni2uRrLgdAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Took up all my gpu available at colab and was not worth it in the end, results were mediocre for the time and effort spent to get a single score"
      ],
      "metadata": {
        "id": "Z2OQgycegzo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression with lasso for feature selection\n",
        "\n",
        "# Lasso for feature selection\n",
        "#lasso_selector = Lasso(alpha=0.5,max_iter=10000)  # Adjust alpha based on cross-validation\n",
        "#lasso_selector.fit(F, T)\n",
        "\n",
        "# Identify the selected features (non-zero coefficients)\n",
        "#selected_features_mask = lasso_selector.coef_ != 0\n",
        "#selected_features = F[:, selected_features_mask]\n",
        "\n",
        "# Train Linear Regression on selected features\n",
        "#lin_final = LinearRegression()\n",
        "#lin_final.fit(selected_features, T)\n",
        "\n",
        "# Cross-validation on the reduced dataset\n",
        "#cv_scores = cross_val_score(lin_final, selected_features, T, cv=5, scoring='neg_root_mean_squared_error')\n",
        "#rmse_cv = -cv_scores.mean()\n",
        "#print(f\"Cross-validated RMSE (after Lasso feature selection): {rmse_cv}\")\n",
        "\n",
        "# Transform the test set to include only the selected features\n",
        "#df2_selected = df2[:, selected_features_mask]\n",
        "\n",
        "# Make predictions on the test set\n",
        "#predictions = lin_final.predict(df2_selected)\n"
      ],
      "metadata": {
        "id": "7Qy2kIrqg0am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Model\n",
        "#lin_final = LinearRegression()\n",
        "#lin_final.fit(F,T)"
      ],
      "metadata": {
        "id": "z5f4TxTahNuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression didnt perform too badly, but the lack of hyperparameters limited what could be tested with it, used lasso for feature selection but didnt help much"
      ],
      "metadata": {
        "id": "KN8Y20olg6xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Regressor Model\n",
        "#knn_final = KNeighborsRegressor(n_neighbors=60)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
        "#knn_final.fit(F, T)"
      ],
      "metadata": {
        "id": "C_T4z02qhPml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the last classification problem, KNN performed way better here which may be a sign its more suited for regression problems, but again the score wasnt too impressive"
      ],
      "metadata": {
        "id": "i7DKoMkohSlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Regressor Model\n",
        "#tree_final = DecisionTreeRegressor(max_depth=10, min_samples_split=15,min_samples_leaf=3,criterion=\"friedman_mse\",max_features=0.5, random_state=42)  # Adjust max_depth and other parameters as needed\n",
        "#tree_final.fit(F, T)"
      ],
      "metadata": {
        "id": "ISwnkhLRhdTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Really liked decision tree due to its low execution time, also gave really good results but were greatly improved on by random forest"
      ],
      "metadata": {
        "id": "aKZO3DmBhhve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom base estimator\n",
        "#base_est = DecisionTreeRegressor(max_depth=5, min_samples_split=10)\n",
        "\n",
        "# AdaBoost with a custom base estimator\n",
        "#ada_final = AdaBoostRegressor(estimator=base_est,n_estimators=500,learning_rate=0.05,random_state=42)\n",
        "#ada_final.fit(F, T)"
      ],
      "metadata": {
        "id": "rn1NN7OYhqSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost execution took way too long and didnt have enough tiome to test it thoroughly, but from what i could test of it, performed really well but not the best"
      ],
      "metadata": {
        "id": "dsMPgsvfhz9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient boosting\n",
        "#gb_final = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, max_depth=5, min_samples_split=10 , min_samples_leaf=5, subsample=0.8, random_state=42);\n",
        "#gb_final.fit(F, T);"
      ],
      "metadata": {
        "id": "evIBT3eAh4dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Took even longer than adaboost, i had trouble configuring GPU usage so i couldnt do much with this, results not worth execution times"
      ],
      "metadata": {
        "id": "mjrIqIAciGfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XG boost model\n",
        "#xgb_final = XGBRegressor(n_estimators=80, learning_rate=0.05, max_depth=7, subsample=0.8, colsample_bytree=0.8, random_state=42, objective=\"reg:squarederror\");\n",
        "#xgb_final.fit(F, T);"
      ],
      "metadata": {
        "id": "ZLPp1iRXiHX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performed really well, would have probably been my best algorithm if not for random forest, tuned the parameters to max via cv scores but wasnt that helpful in the end, low execution times aswell"
      ],
      "metadata": {
        "id": "bhlWRs_YiKEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Early Stopping callback\n",
        "#early_stop = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
        "\n",
        "#nn_final = Sequential([Dense(128, activation='relu', input_shape=(F.shape[1],)), Dropout(0.3), Dense(128, activation='relu'), Dropout(0.3), Dense(1)])\n",
        "#nn_final.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "#nn_final.fit(F, T, validation_data=(F, T), epochs=100, batch_size=128, verbose=1,callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "f4MvVx70iWqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Had alot of hope for this one, execution times also very favourable but couldnt get the most out of it in the end, maybe could have been the best one if given more time to execute and tune"
      ],
      "metadata": {
        "id": "jdP8gZDqibd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Early Stopping callback\n",
        "#early_stop = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True )\n",
        "\n",
        "# Neural Network\n",
        "#nn_final = Sequential([Dense(256, activation='swish', input_shape=(F.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(1e-4)),Dropout(0.3),Dense(128, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),Dropout(0.3),Dense(64, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),Dense(1)])\n",
        "\n",
        "#nn_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# Train the model with Early Stopping\n",
        "#nn_final.fit(F, T, validation_split=0.2, epochs=60, batch_size=64, verbose=1, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "T0kFqfFlioLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempted neural networks with swish, not much better , but again fast execution times"
      ],
      "metadata": {
        "id": "NKWE2lcFjN0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Best performance code**\n",
        "Includes best hyperparameters, model(s), imputation scaling etc for the best produced resulting code"
      ],
      "metadata": {
        "id": "HzMsdIhkjcyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Option 3: KNN imputation (best submission)\n",
        "imputer = KNNImputer(n_neighbors=10)\n",
        "F = imputer.fit_transform(F)\n",
        "df2 = imputer.fit_transform(df2)"
      ],
      "metadata": {
        "id": "HCv6-sTQjdtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best imputation technique out of the three used, 10 was the perfect amount of neighbors, any higher or lower messed up the score."
      ],
      "metadata": {
        "id": "OybY-naEjpK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMax Scaler\n",
        "scaler = MinMaxScaler()\n",
        "F = scaler.fit_transform(F)\n",
        "df2 = scaler.fit_transform(df2)"
      ],
      "metadata": {
        "id": "w9Y-bqU1jtQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best scaling technique out of the three used, the other two performed very well but not well enough to be selected for best submission."
      ],
      "metadata": {
        "id": "DHoz-1wpj0dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest regressor\n",
        "rf_final = RandomForestRegressor(n_estimators=500, max_depth=10, min_samples_split=15, min_samples_leaf=3, max_features=0.5, random_state=42, n_jobs=-1 )\n",
        "rf_final.fit(F, T)"
      ],
      "metadata": {
        "id": "lFVAI7Umk5qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best performing algorithm , close competer with XGboost. Took way too long for executions so couldn't fine tune the hyperparameters enough but still gave the best results in the end."
      ],
      "metadata": {
        "id": "friE-Qdnk-4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE using cross-validation\n",
        "cv_scores = cross_val_score(rf_final, F, T, cv=5, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "# Convert negative RMSE to positive and compute the mean RMSE\n",
        "rmse_cv = -cv_scores.mean()\n",
        "print(f\"Cross-validated RMSE: {rmse_cv}\")"
      ],
      "metadata": {
        "id": "F4_OkYo_lNer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used cross validation with negative rmse then converted to positive to get an estimate of performance of my hyperparameters."
      ],
      "metadata": {
        "id": "qduNH9pmlR3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set (df2)\n",
        "predictions = rf_final.predict(df2)\n",
        "\n",
        "# Prepare the submission file\n",
        "# The submission file should have the 'ID' column from df2 and the predicted 'price_doc'\n",
        "submission = sample_submission.copy()\n",
        "\n",
        "# Ensure that we include the 'ID' column from df2 in the submission\n",
        "submission['row ID'] = test_ids  # Use 'ID' from the test set\n",
        "submission['price_doc'] = predictions  # Add the predicted price_doc values\n",
        "\n",
        "# Save the submission file to a CSV\n",
        "submission.to_csv(\"/content/drive/MyDrive/submission_rf.csv\", index=False)"
      ],
      "metadata": {
        "id": "ZSFk-u0oliGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally used the model to predict values and input them in the submission file"
      ],
      "metadata": {
        "id": "u0GGCOTVlsEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final thoughts and major issues faced**\n",
        "\n",
        "\n",
        "*   Time constraints, due to many of these codes taking hours to run, submissions wwere limited, GPU usage didnt always help with executuon times\n",
        "*   GPU usage further caused issues when polynomial was run, it took up most to all of colab GPU so resorted to CPU usage in the end\n",
        "*   Still think more time with neural networks cpould produce amazing results but again not enough time\n",
        "*   Converting from categorical to one hot took up alot of cpu usage and would often crash so had to use alot of gpu for that aswell\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPSSdEjOmB2k"
      }
    }
  ]
}